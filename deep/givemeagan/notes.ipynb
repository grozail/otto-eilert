{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as tnn\n",
    "import torch.cuda\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.utils as visutils\n",
    "from torchvision import transforms, datasets\n",
    "import torch.autograd as agrad\n",
    "# import torch.backends.cudnn as cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first\t torch.Size([1, 64, 2, 2])\nsecond\t torch.Size([1, 64, 4, 4])\nthird\t torch.Size([1, 32, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "inp = agrad.Variable(torch.randn(1, 100, 1, 1))\n",
    "m = tnn.ConvTranspose2d(100, 64, 2, 1, 0, bias=False)\n",
    "output = m(inp)\n",
    "print('first\\t', output.size())\n",
    "m1 = tnn.ConvTranspose2d(64, 64, 4, 2, 1, bias=False)\n",
    "output = m1(output)\n",
    "print('second\\t', output.size())\n",
    "m2 = tnn.ConvTranspose2d(64, 32, 4, 2, 0, bias=False)\n",
    "output = m2(output)\n",
    "print('third\\t', output.size())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'agrad' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2153f2b4edb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m33\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'agrad' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "c = agrad.Variable(torch.randn(1, 33, 1, 1))\n",
    "a = torch.cat((inp, c), 1)\n",
    "print(a.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'agrad' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-be60d0e4aa89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mD_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m D_net = tnn.Sequential(\n\u001b[1;32m      4\u001b[0m             \u001b[0;31m# input signals 1 x 32 x 32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mtnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'agrad' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "n_features = 64\n",
    "D_in = agrad.Variable(torch.randn(10, 1, 32, 32))\n",
    "D_net = tnn.Sequential(\n",
    "            # input signals 1 x 32 x 32\n",
    "            tnn.Conv2d(1, n_features, 4, 2, 1, bias=False),\n",
    "            # n_features x 16 x 16\n",
    "            tnn.Conv2d(n_features, n_features * 2, 4, 2, 1, bias=False),\n",
    "            # n_features * 2 x 8 x 8\n",
    "            tnn.Conv2d(n_features * 2, n_features * 4, 4, 2, 1, bias=False),\n",
    "            # n_features * 4 x 4 x 4\n",
    "            tnn.Conv2d(n_features * 4, 1, 4, 1, 0, bias=False),\n",
    "            tnn.Sigmoid(),\n",
    "        )\n",
    "D_out = D_net(D_in)\n",
    "print(D_out.size())\n",
    "print(D_out.view(-1, 1).squeeze(1).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/ProjectsPy/0_DATASETS/Cyrillic-small/А/A.0.png\nNone\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-01e58c352226>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mopencv_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/opt/ProjectsPy/0_DATASETS/Cyrillic-small/А/A.0.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-01e58c352226>\u001b[0m in \u001b[0;36mopencv_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mchannels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"F\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "def opencv_loader(path):\n",
    "    import cv2 as cv\n",
    "    from PIL import Image\n",
    "    import numpy as np\n",
    "    print(path)\n",
    "    img = cv.imread(path)\n",
    "    print(img)\n",
    "    channels = cv.split(img)\n",
    "    data = channels[0] / 255.0\n",
    "    print(data)\n",
    "    return Image.fromarray(data, \"F\")\n",
    "\n",
    "\n",
    "opencv_loader('/opt/ProjectsPy/0_DATASETS/Cyrillic-small/А/A.0.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "cyrilic_dataset = datasets.ImageFolder(root='/opt/ProjectsPy/0_DATASETS/Cyrillic-small',\n",
    "                                       transform=transforms.ToTensor())\n",
    "dataloader = torch.utils.data.DataLoader(cyrilic_dataset, batch_size, shuffle=True, num_workers=2)\n",
    "iterator = enumerate(dataloader)\n",
    "i, data = iterator.__next__()\n",
    "print(data[0].size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_size = 100\n",
    "n_features = 64\n",
    "GENERATOR = tnn.Sequential(\n",
    "            tnn.ConvTranspose2d(noise_size, n_features * 8, 2, 1, 0, bias=False),\n",
    "            tnn.BatchNorm2d(n_features * 8),\n",
    "            tnn.ReLU(True),\n",
    "            # n_features* 8 x 2 x 2\n",
    "            tnn.ConvTranspose2d(n_features * 8, n_features * 4, 4, 2, 1, bias=False),\n",
    "            tnn.BatchNorm2d(n_features * 4),\n",
    "            tnn.ReLU(True),\n",
    "            # n_features * 4 x 4 x 4\n",
    "            tnn.ConvTranspose2d(n_features * 4, n_features * 2, 4, 2, 1, bias=False),\n",
    "            tnn.BatchNorm2d(n_features * 2),\n",
    "            tnn.ReLU(True),\n",
    "            # n_features x 2 x 8 x 8\n",
    "            tnn.ConvTranspose2d(n_features * 2, n_features, 4, 2, 1, bias=False),\n",
    "            tnn.BatchNorm2d(n_features),\n",
    "            tnn.ReLU(True),\n",
    "            # n_features x 16 x 16\n",
    "            tnn.ConvTranspose2d(n_features, 3, 4, 2, 1, bias=False),\n",
    "            # 3 x 32 x 32\n",
    "            tnn.Tanh(),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "inpg = agrad.Variable(torch.randn(1, 100, 1, 1))\n",
    "print(GENERATOR(inpg).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
